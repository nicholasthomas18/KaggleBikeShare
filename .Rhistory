step_mutate(weather = factor(weather)) |>
step_time(datetime, features = "hour") |>
step_mutate(season = factor(season)) |>
step_corr(all_numeric_predictors(), threshold = 0.5) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = bikedata)
# Print out baked dataset
head(bikedata)
# Make some variables factors
bikedata <- bikedata |>
mutate(weather = factor(weather,
levels = 1:4,
labels = c("Clear",
"Mist/Cloudy",
"Light Rain/Snow",
"Heavy Rain/Snow")))
bikedata <- bikedata |>
mutate(season = factor(season,
levels = 1:4,
labels = c("Spring",
"Summer",
"Fall",
"Winter")))
# No penalty
pregmodel_1 <- linear_reg(penalty = 0, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
# Lets do a Penalized Linear Regression!
library(tidymodels)
# No penalty
pregmodel_1 <- linear_reg(penalty = 0, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
install.packages("glmnet")
# No penalty
pregmodel_1 <- linear_reg(penalty = 0, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
# Let's submit
kaggle_submission <- bind_cols(bike_predictions, testdata) |>
select(datetime, .pred) |>
rename(count = .pred) |>
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
# LASSO
pregmodel_2 <- linear_reg(penalty = 1, mixture = 1) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_2,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Lets do a Penalized Linear Regression!
library(tidymodels)
testdata <- testdata |>
mutate(weather = factor(weather,
levels = 1:4,
labels = c("Clear",
"Mist/Cloudy",
"Light Rain/Snow",
"Heavy Rain/Snow")))
testdata <- testdata |>
mutate(season = factor(season,
levels = 1:4,
labels = c("Spring",
"Summer",
"Fall",
"Winter")))
# LASSO
pregmodel_2 <- linear_reg(penalty = 1, mixture = 1) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_2,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Let's submit
kaggle_submission <- bind_cols(bike_predictions, testdata) |>
select(datetime, .pred) |>
rename(count = .pred) |>
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
# RIDGE
pregmodel_1 <- linear_reg(penalty = 1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_3,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# RIDGE
pregmodel_3 <- linear_reg(penalty = 1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_3,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Let's submit
kaggle_submission <- bind_cols(bike_predictions, testdata) |>
select(datetime, .pred) |>
rename(count = .pred) |>
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
# Elastic Net
pregmodel_1 <- linear_reg(penalty = 1, mixture = .5) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_4,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Elastic Net
pregmodel_4 <- linear_reg(penalty = 1, mixture = .5) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_4,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Let's submit
kaggle_submission <- bind_cols(bike_predictions, testdata) |>
select(datetime, .pred) |>
rename(count = .pred) |>
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
# Small Penalty
pregmodel_5 <- linear_reg(penalty = 0.1, mixture = .5) |>
set_engine("glmnet") |>
set_mode("regression") |>
fit(formula = count ~ ., data = bikedata)
bike_predictions <- predict(pregmodel_5,
new_data = testdata) |>
mutate(.pred = exp(.pred))
# Let's submit
kaggle_submission <- bind_cols(bike_predictions, testdata) |>
select(datetime, .pred) |>
rename(count = .pred) |>
mutate(count = pmax(0, count),
datetime = as.character(format(datetime)))
vroom_write(x=kaggle_submission, file="./LinearPreds.csv", delim=",")
library(mvtnorm)
install.packages("mvtnorm")
library(mvtnorm)
pmvnorm(mean = c(10, 30),
sigma = matrix(c(4, .3(2*5), .3(2*5), 25)),
nrow = 2, byrow = TRUE)
pmvnorm(mean = c(10, 30),
sigma = matrix(c(4, 3, 3, 25)),
nrow = 2, byrow = TRUE)
library(mvtnorm)
pmvnorm(mean = c(10, 30),
sigma = matrix(c(4, 3, 3, 25)),
nrow = 2, byrow = TRUE)
pmvnorm(mean = c(10, 30),
sigma = matrix(c(4, 3, 3, 25)),
nrow = 2, byrow = TRUE),
library(mvtnorm)
pmvnorm(lower = c(12, 31),
upper = c(Inf, Inf),
mean  = c(10, 30),
sigma = matrix(c(4, 3,
3, 25),
nrow = 2, byrow = TRUE))
install.packages("tinytex")
3/3
quarto install tinytex
(13/28) + (2/28)
# Define x values
x_vals <- 0:7
pmf <- dbinom(x, size = 7, prob = 0.6)
pmf <- dbinom(x_vals, size = 7, prob = 0.6)
barplot(pmf)
barplot(pmf, names.arg = x_vals)
barplot(pmf,
xlab = "x", ylab = "P(X = x)",
main = "PMF of X ~ Binomial(7, 0.6)",
ylim = c(0, max(pmf) * 1.12))
barplot(pmf,
xlab = "x", ylab = "P(X = x)",
main = "PMF of X ~ Binomial(7, 0.6)")
text(x = seq_along(x), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
text(x_vals = seq_along(x_vals), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
text(x_vals = seq_along(x_vals), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
text(x = seq_along(x_vals), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
text(x = seq_along(x), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
text(x = seq_along(x_vals), y = pmf, labels = round(pmf, 3), pos = 3, cex = 0.8)
# Plot the pmf
barplot(pmf,
xlab = "x", ylab = "P(X = x)",
main = "PMF of X ~ Binomial(7, 0.6)")
# Plot the pmf
barplot(pmf,
xlab = "x", ylab = "P(X = x)",
main = "PMF of X ~ Binomial(n = 7, p = 0.6)")
# Calculate mean
sum(x * pmf)
# Calculate mean
sum(x_vals * pmf)
# Plot the pmf
barplot(pmf, names.arg = x_vals,
xlab = "x", ylab = "P(X = x)",
main = "PMF of X ~ Binomial(n = 7, p = 0.6)")
# Compute pdf values
pdf_vals <- dexp(x_vals, rate = 1/100)
# Define x values
x_vals <- seq(0, 500, by = 1)
# Compute pdf values
pdf_vals <- dexp(x_vals, rate = 1/100)
# Plot the pdf
plot(x_vals, pdf_vals, type = "l",
xlab = "x", ylab = "Density",
main = "PDF of X ~ Exponential(rate = 1/100)")
# Plot the pdf
plot(x_vals, pdf_vals, type = "h",
xlab = "x", ylab = "Density",
main = "PDF of X ~ Exponential(rate = 1/100)")
# Define x values
# Compute pdf values
# Plot the pdf
# Compute pdf values
pdf_vals <- (1/100) * exp(x_vals / 100)
# Define x values
x_vals <- seq(-500, 0, by = 1)
# Compute pdf values
pdf_vals <- (1/100) * exp(x_vals / 100)
# Plot the pdf
plot(x_vals, pdf_vals, type = "l",
xlab = "x", ylab = "Density",
main = "PDF of X with support (-âˆž, 0)")
main = "PDF of X)
# Plot the pdf
plot(x_vals, pdf_vals, type = "l",
# Plot the pdf
plot(x_vals, pdf_vals, type = "l",
xlab = "x", ylab = "Density",
main = "PDF of X")
# P(Y < 28.4)
pnorm(28.4, mean = 20, sd = 4)
# P(Y > 14)
pnorm(14, mean = 20, sd = 4, lower.tail = FALSE)
# P(17.4 < Y <= 23.9)
pnorm(23.9, mean = 20, sd = 4) - pnorm(17.4, mean = 20, sd = 4)
# First quartile
qnorm(.25, mean = 20, sd = 4)
# Density at the mode
dnorm(20, mean = 20, sd = 4)
#load in the packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
#bring in the data
bikedata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/train.csv")
testdata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/test.csv")
#DATA WRANGLING HOMEWORK SECTION
# Dump casual and registered
bikedata <- bikedata |>
select(-casual, -registered)
# Change count to log(count)
bikedata <- bikedata |>
mutate(count = log(count))
# Regression Tree!
my_mod <- decision_tree(tree_depth = tune(),
cost_complexity = tune(),
min_n=tune()) |>
set_engine("rpart") |>
set_mode("regression")
# Recipe to recode weather, extract hour, make season factor...
my_recipe <- recipe(count ~., data = bikedata) |>
step_mutate(weather = if_else(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather)) |>
step_time(datetime, features = "hour") |>
step_mutate(season = factor(season)) |>
step_corr(all_numeric_predictors(), threshold = 0.5) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = bikedata)
# Load in Packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
# Bring in Data
bikedata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/train.csv")
testdata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/test.csv")
# Dump casual and registered
bikedata <- bikedata |>
select(-casual, -registered)
# Change count to log(count)
bikedata <- bikedata |>
mutate(count = log(count))
# Load in Packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
# Bring in Data
bikedata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/train.csv")
testdata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/test.csv")
# Data Wrangling
# Dump casual and registered
bikedata <- bikedata |>
select(-casual, -registered)
# Change count to log(count)
bikedata <- bikedata |>
mutate(count = log(count))
# Regression Tree
my_mod <- decision_tree(tree_depth = tune(),
cost_complexity = tune(),
min_n=tune()) |>
set_engine("rpart") |>
set_mode("regression")
# Recipe to recode weather, extract hour, make season factor...
my_recipe <- recipe(count ~., data = bikedata) |>
step_mutate(weather = if_else(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather)) |>
step_time(datetime, features = "hour") |>
step_mutate(season = factor(season)) |>
step_corr(all_numeric_predictors(), threshold = 0.5) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = bikedata)
view(bikedata)
view(bikedata)
dbinom(3, size = 10, prob = .2)
# probability of getting 2, 3, or 4 successes out of 10 with a .2 percent chance of success each time
dbinom(2:4, size = 10, prob = .2)
dbinom(0:10, size = 10, prob = .2)
plot(dbinom(3, size = 10, prob = .2))
library(ggplot2)
# Parameters
n <- 10
theta <- 0.9
# Data frame of values
df <- data.frame(
x = 0:n,
pmf = dbinom(0:n, size = n, prob = theta)
)
# Plot
ggplot(df, aes(x = x, y = pmf)) +
geom_col(fill = "skyblue", color = "black", width = 0.7) +
geom_point(color = "red", size = 3) +
labs(
title = paste("Binomial PMF (n =", n, ", theta =", theta, ")"),
x = "Number of Successes (k)",
y = "P(X = k)"
) +
theme_minimal()
pmf <- dbinom(2:4, size = 10, prob = .2)
plot(pmf)
pmf <- dbinom(0:10, size = 10, prob = .2)
plot(pmf)
pmf <- dbinom(0:10, size = 10, prob = .9)
plot(pmf)
plot(dbinom(3, size = 10, prob = .2))
pmf <- dbinom(0:10, size = 10, prob = .9)
plot(pmf,
main = "Binomial PMF for n = 10 & Theta = 0.9")
pmf <- dbinom(0:10, size = 10, prob = .9)
plot(pmf, type = "h",
main = "Binomial PMF for n = 10 & Theta = 0.9")
plot(0:10, pmf, type = "h",
main = "Binomial PMF for n = 10 & Theta = 0.9")
# plot binomial pmf for n = 10 and theta = 0.85
pmf <- dbinom(0:10, size = 10, prob = 0.85)
plot(0:10, pmf, type = "h",
main = "Binomial PMF for n = 10 & Theta = 0.85")
dbinom(7, 10, 0.9)
dbinom(7, 10, 0.85)
plot(0:10, seq(from 0, to = 1, length.out = 1001), prob = 0.85)
plot(0:10, seq(from 0, to = 1, length.out = 1001), dbinom(7, 10, 0.9))
plot(seq(from 0, to = 1, length.out = 1001), dbinom(7, 10, 0.9))
thetas <- seq(0, 1, length.out = 1000)
likelihood <- dbinom(7, 10, 0.9)
plot(seq(thetas, likelihood)
thetas <- seq(0, 1, length.out = 1000)
thetas <- seq(0, 1, length.out = 1000)
likelihood <- dbinom(7, 10, thetas)
plot(seq(thetas, likelihood)
plot(seq(thetas, likelihood))
plot(thetas, likelihood))
plot(thetas, likelihood)
# Load in Packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
# Bring in Data
bikedata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/train.csv")
testdata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/test.csv")
# Data Wrangling
# Dump casual and registered
bikedata <- bikedata |>
select(-casual, -registered)
# Change count to log(count)
bikedata <- bikedata |>
mutate(count = log(count))
# Regression Tree
my_mod <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) |>
set_engine("ranger") |>
set_mode("regression")
# Recipe to recode weather, extract hour, make season factor...
my_recipe <- recipe(count ~., data = bikedata) |>
step_mutate(weather = if_else(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather)) |>
step_time(datetime, features = "hour") |>
step_mutate(season = factor(season)) |>
step_corr(all_numeric_predictors(), threshold = 0.5) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = bikedata)
# Regression Tree
my_mod <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) |>
set_engine("ranger") |>
set_mode("regression")
forrest_wf <- workflow() |>
add_recipe(my_recipe) |>
add_model(my_mod)
View(forrest_wf)
# Load in Packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
# Bring in Data
bikedata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/train.csv")
testdata <- vroom("/Users/nicholasthomas/Desktop/STATISTICS/STAT 348/BikeShare/bike-sharing-demand/test.csv")
# Data Wrangling
# Dump casual and registered
bikedata <- bikedata |>
select(-casual, -registered)
# Change count to log(count)
bikedata <- bikedata |>
mutate(count = log(count))
# Recipe to recode weather, extract hour, make season factor...
my_recipe <- recipe(count ~., data = bikedata) |>
step_mutate(weather = if_else(weather == 4, 3, weather)) |>
step_mutate(weather = factor(weather)) |>
step_time(datetime, features = "hour") |>
step_mutate(season = factor(season)) |>
step_corr(all_numeric_predictors(), threshold = 0.5) |>
step_dummy(all_nominal_predictors()) |>
step_normalize(all_numeric_predictors())
prepped_recipe <- prep(my_recipe)
bake(prepped_recipe, new_data = bikedata)
# Run the Cross Validation
forest_CV_results <- forest_wf |>
tune_grid(
resamples = folds,
grid = forest_grid,
metrics = metric_set(rmse)
)
# Regression Tree
my_mod <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) |>
set_engine("ranger") |>
set_mode("regression")
forest_wf <- workflow() |>
add_recipe(my_recipe) |>
add_model(my_mod)
# Create a grid of tuning values
forest_grid <- grid_regular(mtry(range = c(1, 13)),
min_n(),
levels = 5)
folds <- vfold_cv(trainData, v = 5, repeats=1)
folds <- vfold_cv(bikedata, v = 5, repeats=1)
# Run the Cross Validation
forest_CV_results <- forest_wf |>
tune_grid(
resamples = folds,
grid = forest_grid,
metrics = metric_set(rmse)
)
install.packages("ranger")
# Load in Packages
library(tidyverse)
library(tidymodels)
library(vroom)
library(patchwork)
library(lubridate)
library(ranger)
folds <- vfold_cv(bikedata, v = 5, repeats=1)
# Run the Cross Validation
forest_CV_results <- forest_wf |>
tune_grid(
resamples = folds,
grid = forest_grid,
metrics = metric_set(rmse)
)
